{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios de Importação BD Sakila – Carga Incremental\n",
    "\n",
    "1.Criar a tabela cp_rental_append, contendo a cópia da tabela rental com os campos rental_id e rental_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "use sakila;\n",
    "\n",
    "create table cp_rental_append select rental_id, rental_date from rental;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Criar a tabela cp_rental_id e cp_rental_date, contendo a cópia da tabela cp_rental_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "create table cp_rental_id select * from cp_rental_append;\n",
    "\n",
    "create table cp_rental_date select * from cp_rental_append;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test3 e visualizar no HDFS\n",
    "\n",
    "3.Importar as tabelas cp_rental_append, cp_rental_id e cp_rental_date com 1 mapeador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop import --connect jdbc:mysql://database/sakila --username root -password secret --wareho\n",
    "use-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_append\n",
    "\n",
    "sqoop import --connect jdbc:mysql://database/sakila --username root -password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_id\n",
    "\n",
    "sqoop import --connect jdbc:mysql://database/sakila --username root -password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar com uso do MySQL\n",
    "\n",
    "4.Executar o sql /db-sql/sakila/insert_rental.sql no container do database\n",
    "\n",
    "$ docker exec -it database bash\n",
    "\n",
    "$ cd /db-sql/sakila\n",
    "\n",
    "$ mysql -psecret < insert_rental.sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test3 e visualizar no HDFS\n",
    "\n",
    "5.Atualizar a tabela cp_rental_append no HDFS anexando os novos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop import --table cp_rental_append --connect jdbc:mysql://database/sakila --username root -password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Atualizar a tabela cp_rental_id no HDFS de acordo com o último registro de rental_id, adicionando apenas os novos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#descobrindo o último registro de rental_id e de rental_date para adicionar novos dados a partir deles\n",
    "sqoop eval --connect jdbc:mysql://database/sakila --username root -password secret --query \"select * from cp_rental_append order by rental_id desc limit 5\"\n",
    "\n",
    "-------------------------------------\n",
    "| rental_id   | rental_date         |\n",
    "-------------------------------------\n",
    "| 16049       | 2005-08-23 22:50:12.0 |\n",
    "| 16048       | 2005-08-23 22:43:07.0 |\n",
    "| 16047       | 2005-08-23 22:42:48.0 |\n",
    "| 16046       | 2005-08-23 22:26:47.0 |\n",
    "| 16045       | 2005-08-23 22:25:26.0 |\n",
    "-------------------------------------\n",
    "\n",
    "sqoop import --table cp_rental_id --connect jdbc:mysql://database/sakila --username root -password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --incremental append --check-column rental_id --last-value 16049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.Atualizar a tabela cp_rental_date no HDFS de acordo com o último registro de rental_date, atualizando os registros a partir desta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop import --table cp_rental_date --connect jdbc:mysql://database/sakila --username root -password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --incremental lastmodified --merge-key rental_id --check-column rental_date --last-value '2005-08-23 22:50:12.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação para o Hive e Exportação - BD Employees\n",
    "\n",
    "1.Importar a tabela employees.titles do MySQL para o diretório /user/aluno/<nome>/data com 1 mapeador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret --warehouse-dir /user/aluno/esther/data -m 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Importar a tabela employees.titles do MySQL para uma tabela Hive no banco de dados seu nome com 1 mapeador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 1 --hive-import --hive-table esther.titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Selecionar os 10 primeiros registros da tabela titles no Hive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -it hive-server bash\n",
    "\n",
    "beeline -u jdbc:hive2://localhost:10000\n",
    "\n",
    "select * from titles limit 10;\n",
    "\n",
    "+----------------+------------------+-------------------+-----------------+\n",
    "| titles.emp_no  |   titles.title   | titles.from_date  | titles.to_date  |\n",
    "+----------------+------------------+-------------------+-----------------+\n",
    "| 10001          | Senior Engineer  | 1986-06-26        | 9999-01-01      |\n",
    "| 10002          | Staff            | 1996-08-03        | 9999-01-01      |\n",
    "| 10003          | Senior Engineer  | 1995-12-03        | 9999-01-01      |\n",
    "| 10004          | Engineer         | 1986-12-01        | 1995-12-01      |\n",
    "| 10004          | Senior Engineer  | 1995-12-01        | 9999-01-01      |\n",
    "| 10005          | Senior Staff     | 1996-09-12        | 9999-01-01      |\n",
    "| 10005          | Staff            | 1989-09-12        | 1996-09-12      |\n",
    "| 10006          | Senior Engineer  | 1990-08-05        | 9999-01-01      |\n",
    "| 10007          | Senior Staff     | 1996-02-11        | 9999-01-01      |\n",
    "| 10007          | Staff            | 1989-02-10        | 1996-02-11      |\n",
    "+----------------+------------------+-------------------+-----------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Deletar os registros da tabela employees.titles do MySQL e verificar se foram apagados, através do Sqoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    " sqoop eval --connect jdbc:mysql://database/employees --username root --password secret --query \"truncate table titles\"\n",
    "\n",
    " sqoop eval --connect jdbc:mysql://database/employees --username root --password secret --query \"select * from titles limit 10\"\n",
    "\n",
    " ----------------------------------------------------------------\n",
    "| emp_no      | title                | from_date  | to_date    |\n",
    "----------------------------------------------------------------\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Exportar os dados do diretório /user/hive/warehouse/<nome>.db/data/titles para a tabela do MySQL  employees.titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop export --table titles --connect jdbc:mysql://database/employees --username root --passw\n",
    "ord secret --export-dir /user/aluno/esther/data/titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Selecionar os 10 primeiros registros registros da tabela employees.titles do MySQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sqoop eval --connect jdbc:mysql://database/employees --username root --password secret --query \"select * from titles limit 10\"\n",
    "\n",
    "----------------------------------------------------------------\n",
    "| emp_no      | title                | from_date  | to_date    |\n",
    "----------------------------------------------------------------\n",
    "| 10001       | Senior Engineer      | 1986-06-26 | 9999-01-01 |\n",
    "| 10002       | Staff                | 1996-08-03 | 9999-01-01 |\n",
    "| 10003       | Senior Engineer      | 1995-12-03 | 9999-01-01 |\n",
    "| 10004       | Engineer             | 1986-12-01 | 1995-12-01 |\n",
    "| 10004       | Senior Engineer      | 1995-12-01 | 9999-01-01 |\n",
    "| 10005       | Senior Staff         | 1996-09-12 | 9999-01-01 |\n",
    "| 10005       | Staff                | 1989-09-12 | 1996-09-12 |\n",
    "| 10006       | Senior Engineer      | 1990-08-05 | 9999-01-01 |\n",
    "| 10007       | Senior Staff         | 1996-02-11 | 9999-01-01 |\n",
    "| 10007       | Staff                | 1989-02-10 | 1996-02-11 |\n",
    "----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
